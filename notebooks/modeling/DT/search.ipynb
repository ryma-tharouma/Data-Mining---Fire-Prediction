{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37e22b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Categorical\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b245563",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dir = \"../../../data/merged\"\n",
    "image_dir = \"../../../images/DT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc29a279",
   "metadata": {},
   "source": [
    "# original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f092207",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = os.path.join(merged_dir, \"train_data.parquet\")\n",
    "train_data = pd.read_parquet(train_file_path)\n",
    "test_file_path = os.path.join(merged_dir, \"test_data.parquet\")\n",
    "test_data = pd.read_parquet(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29998d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "X_train = train_data.drop(columns=['fire','longitude', 'latitude']).to_numpy()\n",
    "y_train = train_data['fire'].to_numpy()\n",
    "\n",
    "X_test = test_data.drop(columns=['fire','longitude', 'latitude']).to_numpy()\n",
    "y_test = test_data['fire'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d84e449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14s\\anaconda3\\envs\\dm-env\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('entropy'), np.int64(30), np.int64(1), np.int64(2)] before, using random point ['entropy', np.int64(13), np.int64(5), np.int64(7)]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best DT params: OrderedDict([('criterion', 'gini'), ('max_depth', 29), ('min_samples_leaf', 1), ('min_samples_split', 2)])\n",
      "Best CV f1_macro: 0.8220159058571891\n",
      "Test f1_macro: 0.8295301268612754\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "# Optimized search space\n",
    "dt_space = {\n",
    "    \"max_depth\": Integer(3, 30),\n",
    "    \"min_samples_split\": Integer(2, 20),\n",
    "    \"min_samples_leaf\": Integer(1, 10),\n",
    "    \"criterion\": Categorical([\"gini\", \"entropy\"])\n",
    "}\n",
    "\n",
    "# Bayesian search\n",
    "dt_bayes = BayesSearchCV(\n",
    "    estimator=dt,\n",
    "    search_spaces=dt_space,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring=\"f1_macro\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit\n",
    "dt_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Best results\n",
    "print(\"Best DT params:\", dt_bayes.best_params_)\n",
    "print(\"Best CV f1_macro:\", dt_bayes.best_score_)\n",
    "\n",
    "# Test evaluation\n",
    "y_pred_dt = dt_bayes.predict(X_test)\n",
    "print(\"Test f1_macro:\", f1_score(y_test, y_pred_dt, average=\"macro\"))\n",
    "\n",
    "# Store all results\n",
    "results_dt = pd.DataFrame(dt_bayes.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "results_dt.to_csv(\"dt_bayes_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aabce0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9719    0.9504    0.9610      7576\n",
      "           1     0.6422    0.7644    0.6980       883\n",
      "\n",
      "    accuracy                         0.9310      8459\n",
      "   macro avg     0.8071    0.8574    0.8295      8459\n",
      "weighted avg     0.9375    0.9310    0.9336      8459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred_dt, target_names=[str(c) for c in set(y_test)], digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e351f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_test_score  std_test_score  param_max_depth  param_min_samples_split  \\\n",
      "29         0.822016        0.004197               29                        2   \n",
      "21         0.821311        0.002833               30                        2   \n",
      "10         0.819900        0.008531               30                        2   \n",
      "16         0.818431        0.008856               28                        2   \n",
      "23         0.818290        0.006884               30                        3   \n",
      "\n",
      "    param_min_samples_leaf param_criterion  \n",
      "29                       1            gini  \n",
      "21                       1            gini  \n",
      "10                       1         entropy  \n",
      "16                       1         entropy  \n",
      "23                       1         entropy  \n"
     ]
    }
   ],
   "source": [
    "# Convert cv results to DataFrame\n",
    "results_dt = pd.DataFrame(dt_bayes.cv_results_)\n",
    "\n",
    "# Sort by best CV score\n",
    "results_dt = results_dt.sort_values(\n",
    "    by=\"mean_test_score\", ascending=False\n",
    ")\n",
    "\n",
    "# Show top 5 configs\n",
    "print(results_dt[\n",
    "    [\"mean_test_score\", \"std_test_score\",\n",
    "     \"param_max_depth\", \"param_min_samples_split\",\n",
    "     \"param_min_samples_leaf\", \"param_criterion\"]\n",
    "].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69328809",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dt.to_csv(\"dt_bayes_original_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c819bb5",
   "metadata": {},
   "source": [
    "# Smote Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b6cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = os.path.join(merged_dir, \"train_smote_tomek.parquet\")\n",
    "train_data = pd.read_parquet(train_file_path)\n",
    "test_file_path = os.path.join(merged_dir, \"test_data.parquet\")\n",
    "test_data = pd.read_parquet(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ddc6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "X_train = train_data.drop(columns=['fire','longitude', 'latitude']).to_numpy()\n",
    "y_train = train_data['fire'].to_numpy()\n",
    "\n",
    "X_test = test_data.drop(columns=['fire','longitude', 'latitude']).to_numpy()\n",
    "y_test = test_data['fire'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1534368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best DT params: OrderedDict([('criterion', 'entropy'), ('max_depth', 30), ('min_samples_leaf', 1), ('min_samples_split', 2)])\n",
      "Best CV f1_macro: 0.957393240843199\n",
      "Test f1_macro: 0.8227563119058698\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "# Optimized search space\n",
    "dt_space = {\n",
    "    \"max_depth\": Integer(3, 30),\n",
    "    \"min_samples_split\": Integer(2, 20),\n",
    "    \"min_samples_leaf\": Integer(1, 10),\n",
    "    \"criterion\": Categorical([\"gini\", \"entropy\"])\n",
    "}\n",
    "\n",
    "# Bayesian search\n",
    "dt_bayes = BayesSearchCV(\n",
    "    estimator=dt,\n",
    "    search_spaces=dt_space,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring=\"f1_macro\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit\n",
    "dt_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Best results\n",
    "print(\"Best DT params:\", dt_bayes.best_params_)\n",
    "print(\"Best CV f1_macro:\", dt_bayes.best_score_)\n",
    "\n",
    "# Test evaluation\n",
    "y_pred_dt = dt_bayes.predict(X_test)\n",
    "print(\"Test f1_macro:\", f1_score(y_test, y_pred_dt, average=\"macro\"))\n",
    "\n",
    "# Store all results\n",
    "results_dt = pd.DataFrame(dt_bayes.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "results_dt.to_csv(\"dt_bayes_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "782398f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.9538    0.9607      7576\n",
      "           1     0.6472    0.7271    0.6848       883\n",
      "\n",
      "    accuracy                         0.9301      8459\n",
      "   macro avg     0.8075    0.8404    0.8228      8459\n",
      "weighted avg     0.9343    0.9301    0.9319      8459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred_dt, target_names=[str(c) for c in set(y_test)], digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33ee1a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_test_score  std_test_score  param_max_depth  param_min_samples_split  \\\n",
      "10         0.957393        0.010655               30                        2   \n",
      "23         0.957211        0.010230               28                        2   \n",
      "29         0.957144        0.010141               27                        2   \n",
      "27         0.957110        0.010269               29                        2   \n",
      "21         0.956548        0.009506               30                        2   \n",
      "\n",
      "    param_min_samples_leaf param_criterion  \n",
      "10                       1         entropy  \n",
      "23                       1         entropy  \n",
      "29                       1         entropy  \n",
      "27                       1         entropy  \n",
      "21                       1            gini  \n"
     ]
    }
   ],
   "source": [
    "# Convert cv results to DataFrame\n",
    "results_dt = pd.DataFrame(dt_bayes.cv_results_)\n",
    "\n",
    "# Sort by best CV score\n",
    "results_dt = results_dt.sort_values(\n",
    "    by=\"mean_test_score\", ascending=False\n",
    ")\n",
    "\n",
    "# Show top 5 configs\n",
    "print(results_dt[\n",
    "    [\"mean_test_score\", \"std_test_score\",\n",
    "     \"param_max_depth\", \"param_min_samples_split\",\n",
    "     \"param_min_samples_leaf\", \"param_criterion\"]\n",
    "].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afd3f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dt.to_csv(\"dt_bayes_sTomek_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
